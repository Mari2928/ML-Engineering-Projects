{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "\n",
    "Import Numpy and cv2 to enable using OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the functions\n",
    "\n",
    "Get the background first using background subtraction technique which is then to be subtracted using frame differencing technique. Please see the comments inside the functions below for the description in detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_background(file_path):\n",
    "    \"\"\"\n",
    "    Get the median frame as the background frame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "    The file path in string.\n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    median_frame : NumPy array\n",
    "    The median frame.\n",
    "    \n",
    "    \"\"\"   \n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    \n",
    "    # randomly select 50 frames for the calculating the median\n",
    "    frame_indices = cap.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=50)\n",
    "    \n",
    "    # store the frames in array\n",
    "    frames = []\n",
    "    for idx in frame_indices:\n",
    "        # set the frame id to read that particular frame\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        frames.append(frame)\n",
    "\n",
    "    # calculate the median\n",
    "    median_frame = np.median(frames, axis=0).astype(np.uint8)\n",
    "    \n",
    "    return median_frame\n",
    "\n",
    "def initialize(file_path):\n",
    "    \"\"\"\n",
    "    Initialize the setting. \n",
    "    Get the background frame and read the video file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "    The file path in string.\n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    background, cap : NumPy array, cv2.VideoCapture\n",
    "    The background frame and the video capture.\n",
    "    \n",
    "    \"\"\"   \n",
    "    # get the background frame\n",
    "    background = get_background(file_path)\n",
    "\n",
    "    # convert the background model to grayscale format\n",
    "    background = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Read the video file\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "\n",
    "    return background, cap\n",
    "\n",
    "\n",
    "def detect_cars(background, cap):\n",
    "    \"\"\"\n",
    "    Detect cars by drawing contour of each car.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    background : NumPy array\n",
    "    The background frame.\n",
    "\n",
    "    cap : cv2.VideoCapture\n",
    "    The video capture.\n",
    "    \n",
    "    \"\"\"       \n",
    "    # the number of consecutive frames per process \n",
    "    consecutive_frame = 8\n",
    "    \n",
    "    frame_count = 0\n",
    "    frame_diff_list = []\n",
    "\n",
    "    while (cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            frame_count += 1\n",
    "            orig_frame = frame.copy()\n",
    "\n",
    "            # convert the frame to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # initialize frame difference list \n",
    "            if frame_count % consecutive_frame == 0 or frame_count == 1:\n",
    "                frame_diff_list = []\n",
    "\n",
    "            # find the difference between current frame and base frame\n",
    "            frame_diff = cv2.absdiff(gray, background)\n",
    "\n",
    "            # thresholding to convert the frame to binary\n",
    "            ret, thres = cv2.threshold(frame_diff, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            # dilate the frame a bit to get some more white area\n",
    "            # makes the detection of contours a bit easier\n",
    "            dilate_frame = cv2.dilate(thres, None, iterations=2)\n",
    "\n",
    "            # append the final result into the `frame_diff_list`\n",
    "            frame_diff_list.append(dilate_frame)\n",
    "\n",
    "            # if we have reached `consecutive_frame` number of frames\n",
    "            if len(frame_diff_list) == consecutive_frame:\n",
    "\n",
    "                # add all the frames in the `frame_diff_list`\n",
    "                sum_frames = sum(frame_diff_list)\n",
    "\n",
    "                # find the contours around the white segmented areas\n",
    "                contours, hierarchy = cv2.findContours(sum_frames, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)            \n",
    "\n",
    "                for contour in contours:\n",
    "\n",
    "                    # skip if contour area size is human           \n",
    "                    if cv2.contourArea(contour) < 3000:\n",
    "                        continue\n",
    "\n",
    "                    # get coordinates from the contours\n",
    "                    (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "                    # draw the bounding boxes\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "                cv2.imshow('Detected Cars', frame)\n",
    "                #out.write(orig_frame)\n",
    "\n",
    "            # Stop the program by pressing 'q'   \n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # destroy all the windows after the loop release the video object\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect moving cars\n",
    "\n",
    "Run below cell to start and press 'q' to stop the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "background, cap = initialize('Traffic_Laramie_1.mp4')\n",
    "\n",
    "detect_cars(background, cap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
