{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "\n",
    "Import Numpy and cv2 to enable using OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the functions\n",
    "\n",
    "Define the function to get the background frame used for frame differencing and background subtraction. Use it to initialize the setting and to detect cars going to the city centre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_background(file_path):\n",
    "    \"\"\"\n",
    "    Get the median frame as the background frame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "    The file path in string.\n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    median_frame : NumPy array\n",
    "    The median frame.\n",
    "    \n",
    "    \"\"\"   \n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    \n",
    "    # randomly select 50 frames for the calculating the median\n",
    "    frame_indices = cap.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=50)\n",
    "    \n",
    "    # store the frames in array\n",
    "    frames = []\n",
    "    for idx in frame_indices:\n",
    "        # set the frame id to read that particular frame\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        frames.append(frame)\n",
    "\n",
    "    # calculate the median\n",
    "    median_frame = np.median(frames, axis=0).astype(np.uint8)\n",
    "    \n",
    "    return median_frame\n",
    "\n",
    "\n",
    "def initialize(file_path):\n",
    "    \"\"\"\n",
    "    Initialize the setting. \n",
    "    Get the background frame and read the video file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "    The file path in string.\n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    background, cap : NumPy array, cv2.VideoCapture\n",
    "    The background frame and the video capture.\n",
    "    \n",
    "    \"\"\"       \n",
    "    # get the background frame\n",
    "    background = get_background(file_path)\n",
    "\n",
    "    # convert the background model to grayscale format\n",
    "    background = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Read the video file\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "\n",
    "    return background, cap\n",
    "\n",
    "\n",
    "def detect_cars_going_to_cityCentre(background, cap, consecutive_frame):\n",
    "    \"\"\"\n",
    "    Detect cars going to the city centre and count them.\n",
    "    Print the detection history and the count result.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    background : NumPy array\n",
    "    The background frame.\n",
    "\n",
    "    cap : cv2.VideoCapture\n",
    "    The video capture.\n",
    "    \n",
    "    consecutive_frame : int\n",
    "    The number of consecutive frame per process.\n",
    "    \n",
    "    \"\"\"       \n",
    "    frame_count = 0\n",
    "    car_count = 0\n",
    "    frame_diff_list = []\n",
    "\n",
    "    # get duration of the video in second\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) \n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = frame_count/fps\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret == True:       \n",
    "\n",
    "            frame_count += 1\n",
    "            orig_frame = frame.copy()        \n",
    "\n",
    "            # convert the frame to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # initialize frame difference list \n",
    "            if frame_count == 1 or frame_count % consecutive_frame == 0:\n",
    "                frame_diff_list = []\n",
    "\n",
    "            # find the difference between current frame and base frame\n",
    "            frame_diff = cv2.absdiff(gray, background)\n",
    "\n",
    "            # thresholding to convert the frame to binary\n",
    "            ret, thres = cv2.threshold(frame_diff, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            # dilate the frame a bit to get some more white area...\n",
    "            # ... makes the detection of contours a bit easier\n",
    "            dilate_frame = cv2.dilate(thres, None, iterations=2)\n",
    "\n",
    "\n",
    "            # append the final result into the `frame_diff_list`\n",
    "            frame_diff_list.append(dilate_frame)\n",
    "\n",
    "            # if we have reached `consecutive_frame` number of frames\n",
    "            if len(frame_diff_list) == consecutive_frame:\n",
    "\n",
    "                # add all the frames in the `frame_diff_list`\n",
    "                sum_frames = sum(frame_diff_list)\n",
    "\n",
    "                # find the contours around the white segmented areas\n",
    "                contours, hierarchy = cv2.findContours(sum_frames, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)            \n",
    "\n",
    "                for contour in contours:   \n",
    "\n",
    "                    # get coordinates from the contour\n",
    "                    (x, y, w, h) = cv2.boundingRect(contour)\n",
    "                    \n",
    "                    # count if it's car and is passing by the detection area\n",
    "                    if (x >= 460) and (x <= 490) and (y >= 350) and (y <= 420) and cv2.contourArea(contour) >= 3000:                    \n",
    "                        car_count+=1\n",
    "                        print('detected', car_count)\n",
    "                        # draw the bounding boxes\n",
    "                        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)               \n",
    "\n",
    "            # show frame that indicates detection area\n",
    "            cv2.rectangle(frame, (460, 350), (490, 420), (0, 255, 0), 2) \n",
    "            cv2.imshow('video', frame)          \n",
    "\n",
    "            # stop the program by pressing 'q'   \n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # destroy all the windows after the loop release the video object\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Print the results\n",
    "    print('Total number of cars: ', car_count)\n",
    "    print('Duration in second: ', duration)\n",
    "    print('Cars per minute: ', int((car_count / duration) * 60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect cars going to the city centre\n",
    "\n",
    "Print the history of detections, the total number of cars, duration in second, and calculate the number of cars per minute.\n",
    "\n",
    "## Video 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected 1\n",
      "detected 2\n",
      "detected 3\n",
      "detected 4\n",
      "detected 5\n",
      "detected 6\n",
      "Total number of cars:  6\n",
      "Duration in second:  177.92\n",
      "Cars per minute:  2\n"
     ]
    }
   ],
   "source": [
    "background, cap = initialize('Traffic_Laramie_1.mp4')\n",
    "\n",
    "# the number of consecutive frames per process \n",
    "# set 5 as car speed is slower\n",
    "consecutive_frame = 5\n",
    "\n",
    "detect_cars_going_to_cityCentre(background, cap, consecutive_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected 1\n",
      "detected 2\n",
      "detected 3\n",
      "detected 4\n",
      "Total number of cars:  4\n",
      "Duration in second:  105.68\n",
      "Cars per minute:  2\n"
     ]
    }
   ],
   "source": [
    "background, cap = initialize('Traffic_Laramie_2.mp4')\n",
    "\n",
    "# set 4 as car speed is faster \n",
    "consecutive_frame = 4\n",
    "\n",
    "detect_cars_going_to_cityCentre(background, cap, consecutive_frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
